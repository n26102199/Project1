{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Music-emotion'...\n",
      "remote: Enumerating objects: 490, done.\u001b[K\n",
      "remote: Counting objects: 100% (490/490), done.\u001b[K\n",
      "remote: Compressing objects: 100% (488/488), done.\u001b[K\n",
      "remote: Total 490 (delta 0), reused 490 (delta 0), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (490/490), 520.56 MiB | 13.97 MiB/s, done.\n",
      "Updating files: 100% (457/457), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/IanChen5273/Music-emotion.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KmdlS2pOijVX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 03:41:08.325947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 03:41:09.220759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-24 03:41:09.555332: E tensorflow/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-11-24 03:41:09.555378: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: d405b9cc8598\n",
      "2021-11-24 03:41:09.555384: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: d405b9cc8598\n",
      "2021-11-24 03:41:09.555521: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 470.57.2\n",
      "2021-11-24 03:41:09.555539: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.27.4\n",
      "2021-11-24 03:41:09.555544: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 460.27.4 does not match DSO version 470.57.2 -- cannot find working devices in this configuration\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"請填入自己組別的GPU 代號\"\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "      #tf.config.experimental.set_virtual_devices('GPU')\n",
    "      for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KmdlS2pOijVX"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, BatchNormalization, MaxPooling2D, add, Flatten, Dropout, Dense, GlobalAveragePooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6k9DXNbcimzG"
   },
   "outputs": [],
   "source": [
    "DataPath = '/workspace/Project1/Music-emotion/music-emotion/song/'\n",
    "os.chdir(DataPath)\n",
    "xlsx_module = xlrd.open_workbook('MusicData.xlsx')\n",
    "xlsx_sheet = xlsx_module.sheets()[0]\n",
    "data_info = []\n",
    "for i in range(1, xlsx_sheet.nrows):\n",
    "    data_info.append(xlsx_sheet.row_values(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NikK_XwWW7oc"
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def Train(self, DataPath):\n",
    "        \"\"\"Train data with SVM model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataPath : string\n",
    "            The path where you store the data. Note that the path must contain every split music data and\n",
    "            MusicData.xlsx\n",
    "        \"\"\"\n",
    "        Features, Labels = self.LoadFeature(DataPath)\n",
    "\n",
    "        #MeanValue = np.array(np.mean(Features, axis=0))\n",
    "        #DiffValue = np.array(np.max(Features, axis=0) - np.min(Features, axis=0))\n",
    "        #Features = (Features - MeanValue) / DiffValue\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(Features, Labels, test_size=0.1, random_state=42)\n",
    "\n",
    "        svm_model = svm.SVC(kernel='rbf', C=1, gamma='scale')\n",
    "        svm_model.fit(X_train, y_train.ravel())\n",
    "        joblib.dump(svm_model, 'music00')\n",
    "\n",
    "        print('train = ', svm_model.score(X_train, y_train))\n",
    "        print('val = ', svm_model.score(X_test, y_test))\n",
    "\n",
    "    def Predict(self, ModelPath, InputData):\n",
    "        \"\"\"Predict the input with the given model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ModelPath : string\n",
    "            The path where you store the model.\n",
    "        InputData : string\n",
    "            The path of input data, predict one data at one time.\n",
    "        \"\"\"\n",
    "        X_test = self.FeatureExtraction(InputData)\n",
    "        loaded_model = joblib.load(ModelPath)\n",
    "        result = loaded_model.predict(X_test)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def FeatureExtraction(self, DataPath):\n",
    "        \"\"\"Extract the feature for the given file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataPath : string\n",
    "            The path where your data is, only allows the file of wav and wma format.\n",
    "        \"\"\"\n",
    "        y, sr = librosa.load(DataPath, sr=22050, mono=True, duration=4)\n",
    "        time = librosa.get_duration(y=y, sr=sr)\n",
    "        if int(time) < 4:\n",
    "            return None\n",
    "\n",
    "        feature_mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=sr, n_mfcc=1)\n",
    "        feature_mfcc = feature_mfcc.reshape((1, feature_mfcc.shape[1] * feature_mfcc.shape[0]))\n",
    "        feature_rolloff = librosa.feature.spectral_rolloff(y=y, sr=22050, hop_length=sr, roll_percent=0.85)\n",
    "        feature_spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=22050, hop_length=sr, n_bands=1)\n",
    "        feature_spectral_contrast = feature_spectral_contrast.reshape(\n",
    "            (1, feature_spectral_contrast.shape[1] * feature_spectral_contrast.shape[0]))\n",
    "        feature_rms = librosa.feature.rms(y=y, hop_length=sr)\n",
    "        feature_combine = np.hstack((feature_rms, feature_mfcc))\n",
    "        feature_combine = np.hstack((feature_combine, feature_rolloff))\n",
    "        feature_combine = np.hstack((feature_combine, feature_spectral_contrast))\n",
    "\n",
    "        return feature_combine\n",
    "\n",
    "    def LoadFeature(self, DataPath):\n",
    "        \"\"\"Load features and labels from the directory.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataPath : string\n",
    "            The path where you store the data. Note that the path must contain every split music data and\n",
    "            MusicData.xlsx\n",
    "        \"\"\"\n",
    "        os.chdir(DataPath)\n",
    "        xlsx_module = xlrd.open_workbook('MusicData.xlsx')\n",
    "        xlsx_sheet = xlsx_module.sheets()[0]\n",
    "        data_info = []\n",
    "        for i in range(1, xlsx_sheet.nrows):\n",
    "            data_info.append(xlsx_sheet.row_values(i))\n",
    "\n",
    "        features = np.array([])\n",
    "        music_label = []\n",
    "        for i in range(len(data_info)):\n",
    "            print(\"\\rExtracting feature ({}/{})\".format(i, len(data_info)), flush=True, end='')\n",
    "            print(\" : {}/{}\".format(data_info[i][1], data_info[i][2] + data_info[i][5]), flush=True, end='')\n",
    "\n",
    "            os.chdir(data_info[i][1])\n",
    "\n",
    "            feature = self.FeatureExtraction(data_info[i][2] + data_info[i][5])\n",
    "            os.chdir('..')\n",
    "\n",
    "            if feature is None:\n",
    "                continue\n",
    "\n",
    "            if features.shape[0] == 0:\n",
    "                features = feature\n",
    "            else:\n",
    "                features = np.vstack((features, feature))\n",
    "\n",
    "            arousal_s = data_info[i][3] - 50\n",
    "            valence_s = data_info[i][4] - 50\n",
    "            if arousal_s >= 0 and valence_s >= 0:  # Joy\n",
    "                music_label.append(0)\n",
    "            elif arousal_s >= 0 and valence_s < 0:  # Tension\n",
    "                music_label.append(1)\n",
    "            elif arousal_s < 0 and valence_s >= 0:  # Peacefulness\n",
    "                music_label.append(2)\n",
    "            elif arousal_s < 0 and valence_s < 0:  # Sadness\n",
    "                music_label.append(3)\n",
    "\n",
    "        os.chdir('..')\n",
    "        print('\\rExtract complete', flush=True)\n",
    "\n",
    "        return features, np.array(music_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VHtjGEOeosM9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "model = SVM()\n",
    "# model.Train('/workspace/Project1/Music-emotion/music-emotion/song')\n",
    "result = model.Predict('/workspace/Project1/Music-emotion/music-emotion/music00',DataPath+\"/Four Seasons_Summer 3rd movment/split_002.wav\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rHywW8U2Z-m7"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "class CNN:\n",
    "    def __init__(self, epoch=10, batch_size=8, verbose=1, sr=22050):\n",
    "        self.org_path = os.getcwd()\n",
    "        self.set_epoch = epoch\n",
    "        self.set_batch_size = batch_size\n",
    "        self.set_verbose = verbose\n",
    "        self.sr = sr\n",
    "\n",
    "    def LoadData(self, DataPath):\n",
    "        \"\"\"Load data from the directory.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataPath : string\n",
    "            The path where you store the data. Note that the path must contain every split music data and\n",
    "            MusicData.xlsx\n",
    "        \"\"\"\n",
    "        os.chdir(DataPath)\n",
    "        xlsx_module = xlrd.open_workbook('MusicData.xlsx')\n",
    "        xlsx_sheet = xlsx_module.sheets()[0]\n",
    "        data_info = []\n",
    "        for i in range(1, xlsx_sheet.nrows):\n",
    "            data_info.append(xlsx_sheet.row_values(i))\n",
    "        music_data = []\n",
    "        music_label = []\n",
    "        data_len = []\n",
    "        for i in range(len(data_info)):\n",
    "            # print(\"\\rLoading data ({}/{})\".format(i, len(data_info)), flush=True, end='')\n",
    "            # print(\" : {}/{}\".format(data_info[i][1], data_info[i][2] + data_info[i][5]), flush=True, end='')\n",
    "\n",
    "            os.chdir(data_info[i][1])\n",
    "            # raw_data, sr = librosa.load(data_info[i][2] + data_info[i][5], sr=22050, mono=True, offset=0.0, duration=4)\n",
    "            raw_data, sr = librosa.load(data_info[i][2] + data_info[i][5], sr=self.sr, mono=True, offset=0.0, duration=4)\n",
    "            music_data.append(raw_data)\n",
    "            data_len.append(raw_data.size)\n",
    "            arousal_s = data_info[i][3] - 50\n",
    "            valence_s = data_info[i][4] - 50\n",
    "            if arousal_s >= 0 and valence_s >= 0:  # Joy\n",
    "                music_label.append(0)\n",
    "            elif arousal_s >= 0 and valence_s < 0:  # Tension\n",
    "                music_label.append(1)\n",
    "            elif arousal_s < 0 and valence_s >= 0:  # Peacefulness\n",
    "                music_label.append(2)\n",
    "            elif arousal_s < 0 and valence_s < 0:  # Sadness\n",
    "                music_label.append(3)\n",
    "            os.chdir('..')\n",
    "        music_label = np.array(music_label)\n",
    "        data_len = np.array(data_len)\n",
    "\n",
    "        last_index = np.where(data_len == sr * 4)[0]\n",
    "        new_music_data = []\n",
    "        new_music_label = []\n",
    "        for i in range(last_index.size):\n",
    "            new_music_data.append(music_data[last_index[i]])\n",
    "            new_music_label.append(music_label[i])\n",
    "        new_music_data = np.array(new_music_data)\n",
    "        new_music_label = np.array(new_music_label)\n",
    "\n",
    "        new_music_data = np.reshape(new_music_data, [new_music_label.size, 1, self.sr*4, 1])\n",
    "        train_index, test_index = self.split_data(new_music_label, train_size=0.7)\n",
    "        train_data = new_music_data[train_index, :, :, :]\n",
    "        train_label = to_categorical(new_music_label[train_index])\n",
    "        test_data = new_music_data[test_index, :, :, :]\n",
    "        test_label = to_categorical(new_music_label[test_index])\n",
    "\n",
    "        return train_data, train_label, test_data, test_label\n",
    "\n",
    "    def split_data(self, label, train_size=0.7):\n",
    "        import random\n",
    "        uni_label = np.unique(label)\n",
    "        uni_label_num = [[] for i in range(uni_label.size)]\n",
    "        train_index = np.array([], dtype='uint32')\n",
    "        for i in range(uni_label.size):\n",
    "            uni_label_num = list(np.where(label == uni_label[i])[0])\n",
    "            train_index = np.hstack(\n",
    "                [train_index, np.array(random.sample(uni_label_num, k=int(len(uni_label_num) * train_size)))])\n",
    "        train_index = np.sort(train_index)\n",
    "        test_index = np.setdiff1d(np.arange(label.size), train_index)\n",
    "\n",
    "        return train_index, test_index\n",
    "\n",
    "    def CreateModel(self, InputShape):\n",
    "        \"\"\"Create CNN model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        InputShape :\n",
    "            The shape of training data\n",
    "        \"\"\"\n",
    "        sig_input = Input(shape=InputShape)\n",
    "        x1_1=Conv2D(128,(1,256),kernel_initializer='random_uniform',padding='same',data_format='channels_last')(sig_input)\n",
    "        x1_1=(Activation('relu'))(x1_1)\n",
    "        x1_1=(BatchNormalization())(x1_1)\n",
    "        x1_1=MaxPooling2D((1,80),strides=(1,40),data_format='channels_last')(x1_1)\n",
    "        x1_2=Conv2D(128,(1,512),kernel_initializer='random_uniform',padding='same',data_format='channels_last')(x1_1)\n",
    "        x1_2=(Activation('relu'))(x1_2)\n",
    "        x1_2=(BatchNormalization())(x1_2)\n",
    "        x1_o=add([x1_1,x1_2])\n",
    "        x2=Conv2D(32,(1,1024),kernel_initializer='random_uniform',padding='same',data_format='channels_last')(x1_o)\n",
    "        x2=(Activation('relu'))(x2)\n",
    "        x2=(BatchNormalization())(x2)\n",
    "        x2=MaxPooling2D((1,80),strides=(1,40),data_format='channels_last')(x2)\n",
    "        y=(Flatten())(x2)\n",
    "        y=(Dropout(0.4))(y)\n",
    "        y=(Dense(units=64,activation='relu'))(y)\n",
    "        y=(Dropout(0.4))(y)\n",
    "        output=(Dense(units=4,activation='softmax'))(y)\n",
    "        model = Model(sig_input, output)\n",
    "\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def Train(self, DataPath):\n",
    "        \"\"\"Train data with CNN model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        DataPath : string\n",
    "            The path where you store the data. Note that the path must contain every split music data and\n",
    "            MusicData.xlsx\n",
    "        \"\"\"\n",
    "        train_data, train_label, test_data, test_label = self.LoadData(DataPath)\n",
    "        model = self.CreateModel(train_data.shape[1:])\n",
    "\n",
    "        train_history = model.fit(x=train_data,\n",
    "                                  y=train_label,\n",
    "                                  validation_data=(test_data, test_label),\n",
    "                                  epochs=self.set_epoch,\n",
    "                                  batch_size=self.set_batch_size,\n",
    "                                  verbose=self.set_verbose)\n",
    "        os.chdir(self.org_path)\n",
    "        model.save('music_cnn.model')\n",
    "\n",
    "        # %% Model accuracy\n",
    "        y1 = train_history.history['acc']\n",
    "        y2 = train_history.history['val_acc']\n",
    "        x = np.arange(len(y1)) + 1\n",
    "        plt.plot(x, y1, color='blue', label='Train')\n",
    "        plt.plot(x, y2, color='red', label='Validation')\n",
    "        plt.title(\"accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.legend(loc='upper left', shadow=True)\n",
    "        plt.savefig('accuracy', dpi=1500)\n",
    "        plt.show()\n",
    "\n",
    "        # %% Model loss value\n",
    "        y1 = train_history.history['loss']\n",
    "\n",
    "\n",
    "        y2 = train_history.history['val_loss']\n",
    "        x = np.arange(len(y1)) + 1\n",
    "        plt.plot(x, y1, color='blue', label='Train')\n",
    "        plt.plot(x, y2, color='red', label='Validation')\n",
    "        plt.title(\"loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.legend(loc='upper right', shadow=True)\n",
    "        plt.savefig('loss', dpi=1500)\n",
    "        plt.show()\n",
    "\n",
    "    def Predict(self, ModelPath, InputData):\n",
    "        \"\"\"Predict the input with the given model\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ModelPath : string\n",
    "            The path where you store the model.\n",
    "        InputData : string\n",
    "            The path of input data, predict one data at one time.\n",
    "        \"\"\"\n",
    "        raw_data, sr = librosa.load(InputData, sr=self.sr, mono=True, offset=0.0, duration=4)\n",
    "        model = load_model(ModelPath)\n",
    "        music_data = np.reshape(raw_data, [1, 1, self.sr*4, 1])\n",
    "        score = model.predict(music_data)\n",
    "        pre_label = np.argmax(score)\n",
    "\n",
    "        return pre_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CqUmisRipwbv",
    "outputId": "8bf2b619-0774-4011-970a-38fb359a5b7b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 03:40:04.592186: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2799895000 Hz\n",
      "2021-11-24 03:40:04.597088: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6dd98d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 03:40:04.597157: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-24 03:40:05.482013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6e3d5c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 03:40:05.482103: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): RTX A6000, Compute Capability 8.6\n",
      "2021-11-24 03:40:05.486333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8\n",
      "pciBusID: 0000:a1:00.0\n",
      "2021-11-24 03:40:05.486396: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-24 03:40:05.486438: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-24 03:40:05.486464: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-24 03:40:05.486486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-24 03:40:05.486507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-11-24 03:40:05.486531: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-11-24 03:40:05.486553: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-11-24 03:40:05.493398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2021-11-24 03:40:05.493458: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-11-24 03:40:07.937305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-24 03:40:07.937389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2021-11-24 03:40:07.937397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2021-11-24 03:40:07.945519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 46092 MB memory) -> physical GPU (device: 0, name: RTX A6000, pci bus id: 0000:a1:00.0, compute capability: 8.6)\n",
      "2021-11-24 03:40:13.702036: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2021-11-24 03:40:20.933941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "# model.Train(DataPath)\n",
    "result = model.Predict(DataPath+'/music_cnn.model', DataPath+\"Four Seasons_Summer 3rd movment/split_002.wav\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dW1666Esj3n9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Music_emotion_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
